{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import importlib\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, average_precision_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertConfig, BertModel, InputExample\n",
    "from run_classifier_dataset_utils import convert_examples_to_features, parallel_convert_examples_to_features\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils import data\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "Run the `create_data_bigquery.ipynb` script to generate the following files:\n",
    "\n",
    "- `cohort.h5`:\n",
    "  - Contains one record for each adult patient’s first ICU stay over 48 hours in lengthwithin their first hospital admission.\n",
    "  - The `mort_icu` column represents whether the patient died during their ICU stay.\n",
    "  - The columns from `Acute Renal` to `Shock` correspond to each of the 25 CCS code  groups, which are derived from  ICD-9 codes assigned at the end of a patient’s hospital stay.\n",
    "  - The `Any Acute` and `Any Chronic` columns are derived from whether the patient has any acute and chronic phenotypes respectively.\n",
    "  \n",
    "  \n",
    "- `notes.h5`\n",
    "  - Contains, for each of the patients in `cohort.h5`, all of the notes written during their hospital stay (along with the timestamp) for the following note types:\n",
    "      - Discharge Summary\n",
    "      - Nursing\n",
    "      - Nursing/other\n",
    "  - The notes have been lightly preprocessed (ex: removing PHI identifiers, removing section numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/content/gdrive/My Drive/hst953_hw1/mimic_data'\n",
    "bert_path = '/content/gdrive/My Drive/hst953_hw1/mimic_data/biobert_pretrain_output_all_notes_150000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMaskedLM.from_pretrained(bert_path).to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = pd.read_hdf(os.path.join(data_path, 'cohort.h5'))\n",
    "notes = pd.read_hdf(os.path.join(data_path, 'notes.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_blank(text: str, model: BertForMaskedLM, tokenizer: BertTokenizer) -> (str, dict):\n",
    "    '''\n",
    "    Given a sentence with a single blank (denoted by an underscore), queries the BERT model to \n",
    "        fill in the missing token.\n",
    "        \n",
    "    Inputs:\n",
    "        - text: sentence containing a single underscore corresponding to the missing token\n",
    "                ex: \"[CLS] 40 yo asian homeless man with h/o polysubstance abuse and recently released from _  [SEP]\"\n",
    "        - model: pytorch ClinicalBERT model, of type BertForMaskedLM\n",
    "        - tokenizer: BertTokenizer object\n",
    "    \n",
    "    Output:\n",
    "        - tuple consisting of the following:\n",
    "            - string corresponding to the sentence where the underscore is replaced with the most likely token\n",
    "                ex: \"[CLS] 40 yo asian homeless man with h / o polysubstance abuse and recently released from home [SEP]\"\n",
    "            - a dictionary str:float mapping each word in the vocabulary to its normalized probability.\n",
    "                - sum of the values should be equal to 1\n",
    "                - the dictionary should have 28996 elements\n",
    "    '''\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fill_blank():\n",
    "    text = '[CLS] 40 yo asian homeless man with h/o polysubstance abuse and recently released from _ [SEP]'\n",
    "    a,b = fill_blank(text, model, tokenizer)\n",
    "    assert(a.split(' ')[-2] == 'home'), 'Most likely word not correct!'\n",
    "    assert(math.isclose(np.sum(list(b.values())), 1.0, rel_tol = 1e-4)), 'Probabilities not normalized!'\n",
    "    assert(math.isclose(b['shelter'], 0.021500807255506516, rel_tol = 1e-4)), \"Probability not correct!\"\n",
    "    print(\"Test passed!\")\n",
    "    \n",
    "test_fill_blank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning ClinicalBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting this section, ensure that you are on a Colab GPU runtime with 25 GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload model to output hidden states\n",
    "config = BertConfig.from_pretrained(bert_path, output_hidden_states=True)\n",
    "model = BertModel.from_pretrained(bert_path, config = config).to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_path)\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if device == 'cuda' and n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(notes.groupby(['subject_id', 'hadm_id']).agg({'text':'count'})['text'].value_counts().describe())\n",
    "time_steps = 35 # choose to take most recent 35 notes for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes.loc[notes.category == 'Discharge summary', 'charttime'] = notes[notes.category == 'Discharge summary'].iloc[0]['chartdate'] + pd.Timedelta(days = 1) -  pd.Timedelta(seconds = 1)\n",
    "cohort = cohort.reset_index(drop = True)\n",
    "\n",
    "def index_notes(x):\n",
    "    # take most recent time_steps notes\n",
    "    if len(x) > time_steps:\n",
    "        return np.concatenate((-1*np.ones(len(x) - time_steps), np.arange(time_steps)))\n",
    "    else:\n",
    "        return np.arange(len(x))\n",
    "    \n",
    "notes['note_index'] = -1\n",
    "notes['note_index'] = notes.sort_values(by = ['subject_id','charttime'], ascending = True).groupby('subject_id').transform(index_notes).astype(int)\n",
    "notes = notes[notes.note_index >= 0] # drop excess notes > time_steps\n",
    "\n",
    "mapping = dict(map(reversed, cohort['subject_id'].to_dict().items()))\n",
    "notes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input_example(subject_id, note_ind, text):\n",
    "    return InputExample(guid = '%s-%s'%(subject_id, note_ind), text_a = text, text_b = None, label = 0)\n",
    "\n",
    "examples = [convert_input_example(row['subject_id'], row['note_index'], row['text']) for idx, row in notes.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will take ~(150/n_cpu) min\n",
    "features = parallel_convert_examples_to_features(examples, 512, tokenizer, \n",
    "                                                 output_mode = 'classification', n_cpus = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIMICDataset(data.Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        self.length = len(features)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        all_input_ids = torch.tensor(self.features[index].input_ids, dtype = torch.long)\n",
    "        all_input_mask = torch.tensor(self.features[index].input_mask, dtype = torch.long)\n",
    "        all_segment_ids = torch.tensor(self.features[index].segment_ids, dtype = torch.long)\n",
    "        y = torch.tensor(self.features[index].label_id, dtype = torch.float32)\n",
    "        guid = self.features[index].guid\n",
    "\n",
    "        return all_input_ids, all_input_mask, all_segment_ids, y, guid\n",
    "\n",
    "def extract_embeddings(v):\n",
    "    return torch.cat((v[-1][:, 0, :] , v[-2][:, 0, :] , v[-3][:, 0, :] , v[-4][:, 0, :]), 1)\n",
    "\n",
    "def get_embs(generator):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for input_ids, input_mask, segment_ids, _,  guid in tqdm(generator):\n",
    "            input_ids = input_ids.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            hidden_states = model(input_ids, token_type_ids = segment_ids, attention_mask = input_mask)[2]\n",
    "            bert_out = extract_embeddings(hidden_states)\n",
    "                        \n",
    "            for c,i in enumerate(guid):\n",
    "                sub_id, note_idx = i.split('-')\n",
    "                embs = bert_out[c,:].detach().cpu()\n",
    "                inputs[mapping[int(sub_id)], int(note_idx), :] = embs\n",
    "    return True\n",
    "\n",
    "emb_dim = 768*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.zeros((cohort.shape[0], time_steps, emb_dim)) # num_patient x time_steps x emb_size\n",
    "data_generator = data.DataLoader(MIMICDataset(features), shuffle = True,  batch_size = 64*n_gpu)\n",
    "# will take several hours\n",
    "get_embs(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## might want to cache `inputs` to avoid running the above cell again\n",
    "torch.save(inputs, open('/content/gdrive/My Drive/hst953_hw1/mimic_data/inputs.pt', 'wb'))\n",
    "# inputs = torch.load(open('/content/gdrive/My Drive/hst953_hw1/mimic_data/inputs.pt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = notes.sort_values(by = 'subject_id').groupby('subject_id').agg({'note_index': 'max'})['note_index'].values + 1\n",
    "targets = pd.read_csv('mapping.csv')['after'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort.loc[cohort['train'] == 0, 'split'] = 'test'\n",
    "cohort.loc[(cohort['train'] == 1) & (np.random.rand(len(cohort)) < 0.8), 'split'] = 'train'\n",
    "cohort['split'] = cohort['split'].fillna('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the following to get the 1 point for the first question of part c\n",
    "print(inputs[35, 10, 1234])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Temporal Model\n",
    "To build your model, you have the following variables defined in memory:\n",
    "- `targets`: list of 27 predictive targets corresponding to column names in `cohort`\n",
    "- `cohort`: dataframe containing targets. Make sure to follow the train/val/test split in the `split` column\n",
    "- `inputs`: num_patient x time_steps (35) x emb_size (3076) tensor. Each [i, :, :] slice of the tensor corresponds to a single patient.\n",
    "- `mapping`: maps the `subject_id` field to an index in the `inputs` tensor. For example, the features for the patient with subject_id=3 is at the index=0 slice of `inputs`.\n",
    "- `seq_lengths`: array of size num_patient, where each element represents how many notes (up to 35) the patient had. This is the number of non-zero note embeddings that a patient has in `inputs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "## train model\n",
    "## save model as model.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "test_cohort = cohort[cohort.split == 'test']\n",
    "## evaluate your model on test_cohort here\n",
    "## for each field `i` in targets, write your predictions into a new column called 'pred' + i\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5c table\n",
    "# Run this code and paste the table into your report\n",
    "aucs = []\n",
    "for i in targets:\n",
    "    aucs.append((i, roc_auc_score(test_cohort[i], test_cohort['pred'+i]),\n",
    "                log_loss(test_cohort[i], test_cohort['pred'+i]),\n",
    "                average_precision_score(test_cohort[i], test_cohort['pred'+i])))\n",
    "aucs.append(('Mean', np.mean([i[1] for i in aucs]),np.mean([i[2] for i in aucs]),np.mean([i[3] for i in aucs])))\n",
    "res = pd.DataFrame(aucs, columns = ['Task','AUROC', 'logloss', \"AUPRC\"])\n",
    "res.style.format({\n",
    "    'AUROC': '{:.3f}',\n",
    "    'logloss': '{:.3f}',\n",
    "    'AUPRC': '{:.3f}'\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
